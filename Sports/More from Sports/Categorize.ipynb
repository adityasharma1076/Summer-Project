{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "\n",
    "Today_time = now.strftime(\"%H:%M\")\n",
    "\n",
    "Today_date = now.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./Combine_csv.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_dir ='Combined CSV/'\n",
    "suffix_dir = 'combined_sports-'+Today_date+'.csv'\n",
    "today_csv=os.path.join(prefix_dir+suffix_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Heading</th>\n",
       "      <th>Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hindiustan Times</td>\n",
       "      <td>India vs Pakistan, ICC World Cup 2019: Rohit S...</td>\n",
       "      <td>cricket</td>\n",
       "      <td>2019-06-17</td>\n",
       "      <td>09:23:00</td>\n",
       "      <td>https://www.hindustantimes.com/cricket/india-v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hindiustan Times</td>\n",
       "      <td>ICC World Cup 2019: Bhuvneshwar Kumar ruled fo...</td>\n",
       "      <td>cricket</td>\n",
       "      <td>2019-06-17</td>\n",
       "      <td>08:14:00</td>\n",
       "      <td>https://www.hindustantimes.com/cricket/icc-wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hindiustan Times</td>\n",
       "      <td>India vs Pakistan, ICC World Cup 2019: Rohit S...</td>\n",
       "      <td>cricket</td>\n",
       "      <td>2019-06-17</td>\n",
       "      <td>09:04:00</td>\n",
       "      <td>https://www.hindustantimes.com/cricket/india-v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindiustan Times</td>\n",
       "      <td>India vs Pakistan, ICC World Cup 2019: Shoaib ...</td>\n",
       "      <td>cricket</td>\n",
       "      <td>2019-06-17</td>\n",
       "      <td>14:39:00</td>\n",
       "      <td>https://www.hindustantimes.com/cricket/india-v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hindiustan Times</td>\n",
       "      <td>India vs Pakistan, ICC World Cup 2019: Was Vir...</td>\n",
       "      <td>cricket</td>\n",
       "      <td>2019-06-17</td>\n",
       "      <td>14:29:00</td>\n",
       "      <td>https://www.hindustantimes.com/cricket/india-v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Source                                            Heading  \\\n",
       "0  Hindiustan Times  India vs Pakistan, ICC World Cup 2019: Rohit S...   \n",
       "1  Hindiustan Times  ICC World Cup 2019: Bhuvneshwar Kumar ruled fo...   \n",
       "2  Hindiustan Times  India vs Pakistan, ICC World Cup 2019: Rohit S...   \n",
       "3  Hindiustan Times  India vs Pakistan, ICC World Cup 2019: Shoaib ...   \n",
       "4  Hindiustan Times  India vs Pakistan, ICC World Cup 2019: Was Vir...   \n",
       "\n",
       "  Category        Date      Time  \\\n",
       "0  cricket  2019-06-17  09:23:00   \n",
       "1  cricket  2019-06-17  08:14:00   \n",
       "2  cricket  2019-06-17  09:04:00   \n",
       "3  cricket  2019-06-17  14:39:00   \n",
       "4  cricket  2019-06-17  14:29:00   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://www.hindustantimes.com/cricket/india-v...  \n",
       "1  https://www.hindustantimes.com/cricket/icc-wor...  \n",
       "2  https://www.hindustantimes.com/cricket/india-v...  \n",
       "3  https://www.hindustantimes.com/cricket/india-v...  \n",
       "4  https://www.hindustantimes.com/cricket/india-v...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports = pd.read_csv(today_csv)\n",
    "sports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(691, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sports\n",
    "Heading = df['Heading']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "others               130\n",
       "tennis                92\n",
       "cricket               86\n",
       "football              84\n",
       "athletics             37\n",
       "hockey                37\n",
       "chess                 25\n",
       "wrestling             25\n",
       "shooting              25\n",
       "icc wc 2019           25\n",
       "boxing                25\n",
       "snooker-billiards     25\n",
       "racing                25\n",
       "golf                  25\n",
       "cycling               25\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem.snowball import SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\drago\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\drago\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "stopset = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_apostrophe(data):\n",
    "    return np.char.replace(data, \"'\", \"\")\n",
    "\n",
    "def remove_punctuation(data):\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in range(len(symbols)):\n",
    "        data = np.char.replace(data, symbols[i], ' ')\n",
    "        data = np.char.replace(data, \"  \", \" \")\n",
    "    data = np.char.replace(data, ',', '')\n",
    "    return data\n",
    "\n",
    "def convert_numbers(data):\n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            w = num2words(int(w))\n",
    "        except:\n",
    "            a = 0\n",
    "        new_text = new_text + \" \" + w\n",
    "    new_text = np.char.replace(new_text, \"-\", \" \")\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Heading'] = df['Heading'].apply(remove_apostrophe)\n",
    "df['Heading'] = df['Heading'].apply(remove_punctuation)\n",
    "df['Heading'] = df['Heading'].apply(convert_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "   \n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text):\n",
    "\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "   \n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Heading_stemmed = []\n",
    "Heading_tokenized = []\n",
    "for i in Heading:\n",
    "    allwords_stemmed = tokenize_and_stem(i) #for each item in 'Heading', tokenize/stem\n",
    "    Heading_stemmed.extend(allwords_stemmed) #extend the 'Heading_stemmed' list\n",
    "    \n",
    "    allwords_tokenized = tokenize_only(i)\n",
    "    Heading_tokenized.extend(allwords_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_frame = pd.DataFrame({'words': Heading_tokenized}, index = Heading_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>india</th>\n",
       "      <td>india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vs</th>\n",
       "      <td>vs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pakistan</th>\n",
       "      <td>pakistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>icc</th>\n",
       "      <td>icc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cup</th>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rohit</th>\n",
       "      <td>rohit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharma</th>\n",
       "      <td>sharma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kuldeep</th>\n",
       "      <td>kuldeep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yadav</th>\n",
       "      <td>yadav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             words\n",
       "india        india\n",
       "vs              vs\n",
       "pakistan  pakistan\n",
       "icc            icc\n",
       "world        world\n",
       "cup            cup\n",
       "rohit        rohit\n",
       "sharma      sharma\n",
       "kuldeep    kuldeep\n",
       "yadav        yadav"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_frame.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting and applying algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_n(tfidf_matrix,dist):\n",
    "    \n",
    "    n_clusters = list (range (14,20))\n",
    "    min=999\n",
    "    for n in n_clusters:\n",
    "        km_ss = KMeans(n_clusters=n)\n",
    "        clusters_ss = km_ss.fit_predict(tfidf_matrix)\n",
    "        score = silhouette_score(dist,clusters_ss)\n",
    "        if min>score:\n",
    "            min=score\n",
    "            n_score=n\n",
    "    return n_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict={}\n",
    "for cat in df['Category'].unique():\n",
    "    temp = df[df['Category']==cat].reset_index().drop(['index'],axis=1)\n",
    "    Heading = temp['Heading']\n",
    "    vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,4))\n",
    "    tfidf_matrix = vectorizer.fit_transform(Heading)\n",
    "    \n",
    "    dist = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "    n = get_best_n(tfidf_matrix,dist)\n",
    "    km = KMeans(n_clusters=n)\n",
    "    km.fit(tfidf_matrix)\n",
    "    \n",
    "    clusters = km.labels_.tolist()\n",
    "    temp['Cluster'] = clusters\n",
    " \n",
    "    df_sorted=temp.sort_values(by='Cluster').reset_index()\n",
    "    df_sorted.drop(['index'],axis=1,inplace=True)\n",
    "    \n",
    "    grp = df_sorted.sort_values('Cluster').groupby(['Cluster'],as_index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    cluster_similarity_value =[]\n",
    "    \n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    for i in range(n):\n",
    "        group = grp.get_group(i)\n",
    "\n",
    "        cluster_heading=group['Heading']\n",
    "        cluster_matrix = vectorizer.fit_transform(cluster_heading)\n",
    "        cluster_dist = cosine_similarity(cluster_matrix)\n",
    "        cluster_elements_count = pd.DataFrame.count(group)\n",
    "        x=[]\n",
    "        for i in cluster_dist:\n",
    "\n",
    "            if((cluster_elements_count[0]-1)==0):\n",
    "                y=1\n",
    "            else:\n",
    "                y=float(\"{0:.2f}\".format(((i.sum())/(cluster_elements_count[0]))))\n",
    "            x.append(y)\n",
    "            cluster_similarity_value.append(y)\n",
    "   \n",
    "    \n",
    "    \n",
    "    df_sorted['cluster_similarity_value']=cluster_similarity_value;  col=df_sorted.columns\n",
    "    \n",
    "    grp = df_sorted.sort_values('Cluster').groupby(['Cluster'],as_index=False)\n",
    "    \n",
    "    temp_more =[]\n",
    "    temp_less  =[]\n",
    "    for i in range(n):\n",
    "        cluster = grp.get_group(i)\n",
    "        cluster_mean = cluster['cluster_similarity_value'].mean()\n",
    "        cluster_std = cluster['cluster_similarity_value'].std()\n",
    "        comp_fact = cluster_mean + cluster_std/4\n",
    "        for i in range(len(cluster)):\n",
    "            if (cluster.iloc[i]['cluster_similarity_value']<comp_fact):\n",
    "                temp_less.append(cluster.iloc[i])\n",
    "            else:\n",
    "                temp_more.append(cluster.iloc[i])\n",
    "    df_more_similar=pd.DataFrame(temp_more,columns=col)\n",
    "    df_less_similar=pd.DataFrame(temp_less,columns=col)\n",
    "    \n",
    "    \n",
    "    Result = df_more_similar.sort_values('Cluster').groupby(['Cluster'],as_index=False).apply(lambda x: x.sample(1)) \n",
    "    Result = Result.reset_index().drop(['level_0','level_1'],axis=1)\n",
    "    Result = Result.append(df_less_similar)\n",
    "    Result = Result.sort_values(by='Cluster')\n",
    "    Result = Result.reset_index().drop(['index'],axis=1)\n",
    "    \n",
    "    \n",
    "    df_dict[cat] = Result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for typ,data in df_dict.items():\n",
    "    \n",
    "    outname =typ +'.csv'\n",
    "    root = 'Categorized Output/'\n",
    "    if not os.path.exists(root):\n",
    "        os.mkdir(root)\n",
    "    date_today= Today_date +'/'\n",
    "    outdir=root+ date_today[:-1]\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname)\n",
    "    data.to_csv(fullname,index=False,encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
