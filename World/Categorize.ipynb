{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./Combine_csv.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "\n",
    "Today_time = now.strftime(\"%H:%M\")\n",
    "\n",
    "Today_date = now.strftime(\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_dir =r\"C:\\Users\\drago\\Documents\\GitHub\\Summer-Project\\World\\Combined CSV\\ \"\n",
    "suffix_dir = 'combined_world-'+Today_date+'.csv'\n",
    "today_csv=prefix_dir[:-1] +suffix_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\drago\\\\Documents\\\\GitHub\\\\Summer-Project\\\\World\\\\Combined CSV\\\\combined_world-2019-06-11.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = pd.read_csv(today_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Heading</th>\n",
       "      <th>Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN</td>\n",
       "      <td>Army vet dies in police custody. His body was ...</td>\n",
       "      <td>us</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>00:10</td>\n",
       "      <td>/2019/06/07/us/army-vet-dies-in-custody-organs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN</td>\n",
       "      <td>Police look for mother after newborn found in ...</td>\n",
       "      <td>us</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>00:10</td>\n",
       "      <td>/2019/06/08/us/georgia-baby-india-found-plasti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN</td>\n",
       "      <td>Man in custody in connection with suspected se...</td>\n",
       "      <td>us</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>00:10</td>\n",
       "      <td>/2019/06/08/us/detroit-serial-killer-saturday/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNN</td>\n",
       "      <td>Plane crash kills both people onboard. Dog sur...</td>\n",
       "      <td>us</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>00:10</td>\n",
       "      <td>/2019/06/09/us/new-york-plane-crash-dog-surviv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN</td>\n",
       "      <td>Michigan hotel offers free stay to anyone trav...</td>\n",
       "      <td>us</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>00:10</td>\n",
       "      <td>/2019/06/08/us/yale-hotel-abortion-free-rooms-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Source                                            Heading Category  \\\n",
       "0    CNN  Army vet dies in police custody. His body was ...       us   \n",
       "1    CNN  Police look for mother after newborn found in ...       us   \n",
       "2    CNN  Man in custody in connection with suspected se...       us   \n",
       "3    CNN  Plane crash kills both people onboard. Dog sur...       us   \n",
       "4    CNN  Michigan hotel offers free stay to anyone trav...       us   \n",
       "\n",
       "         Date   Time                                                URL  \n",
       "0  2019-06-11  00:10  /2019/06/07/us/army-vet-dies-in-custody-organs...  \n",
       "1  2019-06-11  00:10  /2019/06/08/us/georgia-baby-india-found-plasti...  \n",
       "2  2019-06-11  00:10  /2019/06/08/us/detroit-serial-killer-saturday/...  \n",
       "3  2019-06-11  00:10  /2019/06/09/us/new-york-plane-crash-dog-surviv...  \n",
       "4  2019-06-11  00:10  /2019/06/08/us/yale-hotel-abortion-free-rooms-...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(955, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=technology[technology['Date']==Today_date]\n",
    "df=world\n",
    "\n",
    "Heading = df['Heading']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Heading</th>\n",
       "      <th>Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN</td>\n",
       "      <td>Army vet dies in police custody. His body was ...</td>\n",
       "      <td>us</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>00:10</td>\n",
       "      <td>/2019/06/07/us/army-vet-dies-in-custody-organs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN</td>\n",
       "      <td>Police look for mother after newborn found in ...</td>\n",
       "      <td>us</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>00:10</td>\n",
       "      <td>/2019/06/08/us/georgia-baby-india-found-plasti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN</td>\n",
       "      <td>Man in custody in connection with suspected se...</td>\n",
       "      <td>us</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>00:10</td>\n",
       "      <td>/2019/06/08/us/detroit-serial-killer-saturday/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNN</td>\n",
       "      <td>Plane crash kills both people onboard. Dog sur...</td>\n",
       "      <td>us</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>00:10</td>\n",
       "      <td>/2019/06/09/us/new-york-plane-crash-dog-surviv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN</td>\n",
       "      <td>Michigan hotel offers free stay to anyone trav...</td>\n",
       "      <td>us</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>00:10</td>\n",
       "      <td>/2019/06/08/us/yale-hotel-abortion-free-rooms-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Source                                            Heading Category  \\\n",
       "0    CNN  Army vet dies in police custody. His body was ...       us   \n",
       "1    CNN  Police look for mother after newborn found in ...       us   \n",
       "2    CNN  Man in custody in connection with suspected se...       us   \n",
       "3    CNN  Plane crash kills both people onboard. Dog sur...       us   \n",
       "4    CNN  Michigan hotel offers free stay to anyone trav...       us   \n",
       "\n",
       "         Date   Time                                                URL  \n",
       "0  2019-06-11  00:10  /2019/06/07/us/army-vet-dies-in-custody-organs...  \n",
       "1  2019-06-11  00:10  /2019/06/08/us/georgia-baby-india-found-plasti...  \n",
       "2  2019-06-11  00:10  /2019/06/08/us/detroit-serial-killer-saturday/...  \n",
       "3  2019-06-11  00:10  /2019/06/09/us/new-york-plane-crash-dog-surviv...  \n",
       "4  2019-06-11  00:10  /2019/06/08/us/yale-hotel-abortion-free-rooms-...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "us                161\n",
       "world              93\n",
       "europe             88\n",
       "china              81\n",
       "uk                 80\n",
       "middle east        66\n",
       "rest of world      50\n",
       "mad, mad world     50\n",
       "pakistan           50\n",
       "south asia         50\n",
       "africa             45\n",
       "asia               44\n",
       "australia          38\n",
       "india              35\n",
       "americas           24\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\drago\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopset = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_apostrophe(data):\n",
    "    return np.char.replace(data, \"'\", \"\")\n",
    "\n",
    "def remove_punctuation(data):\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in range(len(symbols)):\n",
    "        data = np.char.replace(data, symbols[i], ' ')\n",
    "        data = np.char.replace(data, \"  \", \" \")\n",
    "    data = np.char.replace(data, ',', '')\n",
    "    return data\n",
    "\n",
    "def convert_numbers(data):\n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            w = num2words(int(w))\n",
    "        except:\n",
    "            a = 0\n",
    "        new_text = new_text + \" \" + w\n",
    "    new_text = np.char.replace(new_text, \"-\", \" \")\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Delete This\n",
    "#from sklearn.datasets import fetch_20newsgroups\n",
    "#categories = ['rec.sport.baseball']\n",
    "#dataset = fetch_20newsgroups(subset='all',shuffle=True, random_state=42, categories=categories)\n",
    "#corpus=dataset.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Heading'] = df['Heading'].apply(remove_apostrophe)\n",
    "df['Heading'] = df['Heading'].apply(remove_punctuation)\n",
    "df['Heading'] = df['Heading'].apply(convert_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\drago\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "   \n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text):\n",
    "\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "   \n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Heading_stemmed = []\n",
    "Heading_tokenized = []\n",
    "for i in Heading:\n",
    "    allwords_stemmed = tokenize_and_stem(i) #for each item in 'Heading', tokenize/stem\n",
    "    Heading_stemmed.extend(allwords_stemmed) #extend the 'Heading_stemmed' list\n",
    "    \n",
    "    allwords_tokenized = tokenize_only(i)\n",
    "    Heading_tokenized.extend(allwords_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['army',\n",
       " 'vet',\n",
       " 'dies',\n",
       " 'in',\n",
       " 'police',\n",
       " 'custody',\n",
       " 'his',\n",
       " 'body',\n",
       " 'was',\n",
       " 'returned']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " Heading_tokenized[:10]    # 10 out of all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['armi',\n",
       " 'vet',\n",
       " 'die',\n",
       " 'in',\n",
       " 'polic',\n",
       " 'custodi',\n",
       " 'his',\n",
       " 'bodi',\n",
       " 'was',\n",
       " 'return']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Heading_stemmed[:10]  # 10 out of all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_frame = pd.DataFrame({'words': Heading_tokenized}, index = Heading_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>armi</th>\n",
       "      <td>army</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vet</th>\n",
       "      <td>vet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>die</th>\n",
       "      <td>dies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polic</th>\n",
       "      <td>police</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custodi</th>\n",
       "      <td>custody</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>his</th>\n",
       "      <td>his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodi</th>\n",
       "      <td>body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>return</th>\n",
       "      <td>returned</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            words\n",
       "armi         army\n",
       "vet           vet\n",
       "die          dies\n",
       "in             in\n",
       "polic      police\n",
       "custodi   custody\n",
       "his           his\n",
       "bodi         body\n",
       "was           was\n",
       "return   returned"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_frame.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting and applying algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_n(tfidf_matrix,dist):\n",
    "    \n",
    "    n_clusters = list (range (14,20))\n",
    "    min=999\n",
    "    for n in n_clusters:\n",
    "        km_ss = KMeans(n_clusters=n)\n",
    "        clusters_ss = km_ss.fit_predict(tfidf_matrix)\n",
    "        score = silhouette_score(dist,clusters_ss)\n",
    "        if min>score:\n",
    "            min=score\n",
    "            n_score=n\n",
    "    return n_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict={}\n",
    "for cat in df['Category'].unique():\n",
    "    temp = df[df['Category']==cat].reset_index().drop(['index'],axis=1)\n",
    "    Heading = temp['Heading']\n",
    "    vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,4))\n",
    "    tfidf_matrix = vectorizer.fit_transform(Heading)\n",
    "    \n",
    "    dist = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "    n = get_best_n(tfidf_matrix,dist)\n",
    "    km = KMeans(n_clusters=n)\n",
    "    km.fit(tfidf_matrix)\n",
    "    \n",
    "    clusters = km.labels_.tolist()\n",
    "    temp['Cluster'] = clusters\n",
    " \n",
    "    df_sorted=temp.sort_values(by='Cluster').reset_index()\n",
    "    df_sorted.drop(['index'],axis=1,inplace=True)\n",
    "    \n",
    "    grp = df_sorted.sort_values('Cluster').groupby(['Cluster'],as_index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    cluster_similarity_value =[]\n",
    "    \n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    for i in range(n):\n",
    "        group = grp.get_group(i)\n",
    "\n",
    "        cluster_heading=group['Heading']\n",
    "        cluster_matrix = vectorizer.fit_transform(cluster_heading)\n",
    "        cluster_dist = cosine_similarity(cluster_matrix)\n",
    "        cluster_elements_count = pd.DataFrame.count(group)\n",
    "        x=[]\n",
    "        for i in cluster_dist:\n",
    "\n",
    "            if((cluster_elements_count[0]-1)==0):\n",
    "                y=1\n",
    "            else:\n",
    "                y=float(\"{0:.2f}\".format(((i.sum())/(cluster_elements_count[0]))))\n",
    "            x.append(y)\n",
    "            cluster_similarity_value.append(y)\n",
    "   \n",
    "    \n",
    "    \n",
    "    df_sorted['cluster_similarity_value']=cluster_similarity_value;  col=df_sorted.columns\n",
    "    \n",
    "    grp = df_sorted.sort_values('Cluster').groupby(['Cluster'],as_index=False)\n",
    "    \n",
    "    temp_more =[]\n",
    "    temp_less  =[]\n",
    "    for i in range(n):\n",
    "        cluster = grp.get_group(i)\n",
    "        cluster_mean = cluster['cluster_similarity_value'].mean()\n",
    "        for i in range(len(cluster)):\n",
    "            if (cluster.iloc[i]['cluster_similarity_value']<cluster_mean):\n",
    "                temp_less.append(cluster.iloc[i])\n",
    "            else:\n",
    "                temp_more.append(cluster.iloc[i])\n",
    "    df_more_similar=pd.DataFrame(temp_more,columns=col)\n",
    "    df_less_similar=pd.DataFrame(temp_less,columns=col)\n",
    "    \n",
    "    \n",
    "    Result = df_more_similar.sort_values('Cluster').groupby(['Cluster'],as_index=False).apply(lambda x: x.sample(1)) \n",
    "    Result = Result.reset_index().drop(['level_0','level_1'],axis=1)\n",
    "    Result = Result.append(df_less_similar)\n",
    "    Result = Result.sort_values(by='Cluster')\n",
    "    Result = Result.reset_index().drop(['index'],axis=1)\n",
    "    \n",
    "    \n",
    "    df_dict[cat] = Result\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat,data in df_dict.items():\n",
    "    outname =cat+'.csv'\n",
    "    x=r\"C:\\Users\\drago\\Documents\\GitHub\\Summer-Project\\World\\Categorized Output\\ \"\n",
    "    if not os.path.exists(x[:-1]):\n",
    "        os.mkdir(x[:-1])\n",
    "    date_today= Today_date +'\\ '\n",
    "    outdir=x[:-1]+ date_today[:-1]\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir) \n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    \n",
    "    data.to_csv(fullname,index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
