{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./Combine_csv.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "\n",
    "Today_time = now.strftime(\"%H:%M\")\n",
    "\n",
    "Today_date = now.strftime(\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_dir =r\"C:\\Users\\drago\\Documents\\GitHub\\Summer-Project\\Entertainment\\More from Entertainment\\Combined CSV\\ \"\n",
    "suffix_dir = 'combined_entertainment-'+Today_date+'.csv'\n",
    "today_csv=prefix_dir[:-1] +suffix_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\drago\\\\Documents\\\\GitHub\\\\Summer-Project\\\\Entertainment\\\\More from Entertainment\\\\Combined CSV\\\\combined_entertainment-2019-06-11.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "entertainment = pd.read_csv(today_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Heading</th>\n",
       "      <th>Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hindiustan Times</td>\n",
       "      <td>Sonali Bendre shares her experience from aqua ...</td>\n",
       "      <td>bollywood</td>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>21:42:00</td>\n",
       "      <td>https://www.hindustantimes.com/bollywood/sonal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hindiustan Times</td>\n",
       "      <td>Varun Dhawan, Anushka Sharma, Abhishek Bachcha...</td>\n",
       "      <td>bollywood</td>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>21:38:00</td>\n",
       "      <td>https://www.hindustantimes.com/bollywood/varun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hindiustan Times</td>\n",
       "      <td>Disha Patani dines with Aditya Thackeray, Mala...</td>\n",
       "      <td>bollywood</td>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>20:30:00</td>\n",
       "      <td>https://www.hindustantimes.com/bollywood/disha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindiustan Times</td>\n",
       "      <td>When Shah Rukh Khan’s daughter Suhana Khan dan...</td>\n",
       "      <td>bollywood</td>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>18:28:00</td>\n",
       "      <td>https://www.hindustantimes.com/bollywood/when-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hindiustan Times</td>\n",
       "      <td>Meezaan on link-up rumours with Amitabh Bachch...</td>\n",
       "      <td>bollywood</td>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>18:15:00</td>\n",
       "      <td>https://www.hindustantimes.com/bollywood/meeza...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Newspaper                                            Heading  \\\n",
       "0  Hindiustan Times  Sonali Bendre shares her experience from aqua ...   \n",
       "1  Hindiustan Times  Varun Dhawan, Anushka Sharma, Abhishek Bachcha...   \n",
       "2  Hindiustan Times  Disha Patani dines with Aditya Thackeray, Mala...   \n",
       "3  Hindiustan Times  When Shah Rukh Khan’s daughter Suhana Khan dan...   \n",
       "4  Hindiustan Times  Meezaan on link-up rumours with Amitabh Bachch...   \n",
       "\n",
       "    Category        Date      Time  \\\n",
       "0  bollywood  2019-06-10  21:42:00   \n",
       "1  bollywood  2019-06-10  21:38:00   \n",
       "2  bollywood  2019-06-10  20:30:00   \n",
       "3  bollywood  2019-06-10  18:28:00   \n",
       "4  bollywood  2019-06-10  18:15:00   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://www.hindustantimes.com/bollywood/sonal...  \n",
       "1  https://www.hindustantimes.com/bollywood/varun...  \n",
       "2  https://www.hindustantimes.com/bollywood/disha...  \n",
       "3  https://www.hindustantimes.com/bollywood/when-...  \n",
       "4  https://www.hindustantimes.com/bollywood/meeza...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entertainment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entertainment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=technology[technology['Date']==Today_date]\n",
    "df=entertainment\n",
    "\n",
    "Heading = df['Heading']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Heading</th>\n",
       "      <th>Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hindiustan Times</td>\n",
       "      <td>Sonali Bendre shares her experience from aqua ...</td>\n",
       "      <td>bollywood</td>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>21:42:00</td>\n",
       "      <td>https://www.hindustantimes.com/bollywood/sonal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hindiustan Times</td>\n",
       "      <td>Varun Dhawan, Anushka Sharma, Abhishek Bachcha...</td>\n",
       "      <td>bollywood</td>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>21:38:00</td>\n",
       "      <td>https://www.hindustantimes.com/bollywood/varun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hindiustan Times</td>\n",
       "      <td>Disha Patani dines with Aditya Thackeray, Mala...</td>\n",
       "      <td>bollywood</td>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>20:30:00</td>\n",
       "      <td>https://www.hindustantimes.com/bollywood/disha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindiustan Times</td>\n",
       "      <td>When Shah Rukh Khan’s daughter Suhana Khan dan...</td>\n",
       "      <td>bollywood</td>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>18:28:00</td>\n",
       "      <td>https://www.hindustantimes.com/bollywood/when-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hindiustan Times</td>\n",
       "      <td>Meezaan on link-up rumours with Amitabh Bachch...</td>\n",
       "      <td>bollywood</td>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>18:15:00</td>\n",
       "      <td>https://www.hindustantimes.com/bollywood/meeza...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Newspaper                                            Heading  \\\n",
       "0  Hindiustan Times  Sonali Bendre shares her experience from aqua ...   \n",
       "1  Hindiustan Times  Varun Dhawan, Anushka Sharma, Abhishek Bachcha...   \n",
       "2  Hindiustan Times  Disha Patani dines with Aditya Thackeray, Mala...   \n",
       "3  Hindiustan Times  When Shah Rukh Khan’s daughter Suhana Khan dan...   \n",
       "4  Hindiustan Times  Meezaan on link-up rumours with Amitabh Bachch...   \n",
       "\n",
       "    Category        Date      Time  \\\n",
       "0  bollywood  2019-06-10  21:42:00   \n",
       "1  bollywood  2019-06-10  21:38:00   \n",
       "2  bollywood  2019-06-10  20:30:00   \n",
       "3  bollywood  2019-06-10  18:28:00   \n",
       "4  bollywood  2019-06-10  18:15:00   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://www.hindustantimes.com/bollywood/sonal...  \n",
       "1  https://www.hindustantimes.com/bollywood/varun...  \n",
       "2  https://www.hindustantimes.com/bollywood/disha...  \n",
       "3  https://www.hindustantimes.com/bollywood/when-...  \n",
       "4  https://www.hindustantimes.com/bollywood/meeza...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hollywood         162\n",
       "regional          161\n",
       "television         82\n",
       "bollywood          71\n",
       "movie-review       65\n",
       "celebs-gossips     54\n",
       "music              53\n",
       "tamil              26\n",
       "telugu             26\n",
       "malayalam          26\n",
       "web-series         24\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\drago\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopset = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_apostrophe(data):\n",
    "    return np.char.replace(data, \"'\", \"\")\n",
    "\n",
    "def remove_punctuation(data):\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in range(len(symbols)):\n",
    "        data = np.char.replace(data, symbols[i], ' ')\n",
    "        data = np.char.replace(data, \"  \", \" \")\n",
    "    data = np.char.replace(data, ',', '')\n",
    "    return data\n",
    "\n",
    "def convert_numbers(data):\n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            w = num2words(int(w))\n",
    "        except:\n",
    "            a = 0\n",
    "        new_text = new_text + \" \" + w\n",
    "    new_text = np.char.replace(new_text, \"-\", \" \")\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Delete This\n",
    "#from sklearn.datasets import fetch_20newsgroups\n",
    "#categories = ['rec.sport.baseball']\n",
    "#dataset = fetch_20newsgroups(subset='all',shuffle=True, random_state=42, categories=categories)\n",
    "#corpus=dataset.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Heading'] = df['Heading'].apply(remove_apostrophe)\n",
    "df['Heading'] = df['Heading'].apply(remove_punctuation)\n",
    "df['Heading'] = df['Heading'].apply(convert_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\drago\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "   \n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text):\n",
    "\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "   \n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Heading_stemmed = []\n",
    "Heading_tokenized = []\n",
    "for i in Heading:\n",
    "    allwords_stemmed = tokenize_and_stem(i) #for each item in 'Heading', tokenize/stem\n",
    "    Heading_stemmed.extend(allwords_stemmed) #extend the 'Heading_stemmed' list\n",
    "    \n",
    "    allwords_tokenized = tokenize_only(i)\n",
    "    Heading_tokenized.extend(allwords_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sonali',\n",
       " 'bendre',\n",
       " 'shares',\n",
       " 'her',\n",
       " 'experience',\n",
       " 'from',\n",
       " 'aqua',\n",
       " 'therapy',\n",
       " 'session',\n",
       " 'says']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " Heading_tokenized[:10]    # 10 out of all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sonali',\n",
       " 'bendr',\n",
       " 'share',\n",
       " 'her',\n",
       " 'experi',\n",
       " 'from',\n",
       " 'aqua',\n",
       " 'therapi',\n",
       " 'session',\n",
       " 'say']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Heading_stemmed[:10]  # 10 out of all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_frame = pd.DataFrame({'words': Heading_tokenized}, index = Heading_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sonali</th>\n",
       "      <td>sonali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bendr</th>\n",
       "      <td>bendre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>share</th>\n",
       "      <td>shares</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>her</th>\n",
       "      <td>her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experi</th>\n",
       "      <td>experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from</th>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aqua</th>\n",
       "      <td>aqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>therapi</th>\n",
       "      <td>therapy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session</th>\n",
       "      <td>session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>says</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              words\n",
       "sonali       sonali\n",
       "bendr        bendre\n",
       "share        shares\n",
       "her             her\n",
       "experi   experience\n",
       "from           from\n",
       "aqua           aqua\n",
       "therapi     therapy\n",
       "session     session\n",
       "say            says"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_frame.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting and applying algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_n(tfidf_matrix,dist):\n",
    "    \n",
    "    n_clusters = list (range (14,20))\n",
    "    min=999\n",
    "    for n in n_clusters:\n",
    "        km_ss = KMeans(n_clusters=n)\n",
    "        clusters_ss = km_ss.fit_predict(tfidf_matrix)\n",
    "        score = silhouette_score(dist,clusters_ss)\n",
    "        if min>score:\n",
    "            min=score\n",
    "            n_score=n\n",
    "    return n_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict={}\n",
    "for cat in df['Category'].unique():\n",
    "    temp = df[df['Category']==cat].reset_index().drop(['index'],axis=1)\n",
    "    Heading = temp['Heading']\n",
    "    vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,4))\n",
    "    tfidf_matrix = vectorizer.fit_transform(Heading)\n",
    "    \n",
    "    dist = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "    n = get_best_n(tfidf_matrix,dist)\n",
    "    km = KMeans(n_clusters=n)\n",
    "    km.fit(tfidf_matrix)\n",
    "    \n",
    "    clusters = km.labels_.tolist()\n",
    "    temp['Cluster'] = clusters\n",
    " \n",
    "    df_sorted=temp.sort_values(by='Cluster').reset_index()\n",
    "    df_sorted.drop(['index'],axis=1,inplace=True)\n",
    "    \n",
    "    grp = df_sorted.sort_values('Cluster').groupby(['Cluster'],as_index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    cluster_similarity_value =[]\n",
    "    \n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    for i in range(n):\n",
    "        group = grp.get_group(i)\n",
    "\n",
    "        cluster_heading=group['Heading']\n",
    "        cluster_matrix = vectorizer.fit_transform(cluster_heading)\n",
    "        cluster_dist = cosine_similarity(cluster_matrix)\n",
    "        cluster_elements_count = pd.DataFrame.count(group)\n",
    "        x=[]\n",
    "        for i in cluster_dist:\n",
    "\n",
    "            if((cluster_elements_count[0]-1)==0):\n",
    "                y=1\n",
    "            else:\n",
    "                y=float(\"{0:.2f}\".format(((i.sum())/(cluster_elements_count[0]))))\n",
    "            x.append(y)\n",
    "            cluster_similarity_value.append(y)\n",
    "   \n",
    "    \n",
    "    \n",
    "    df_sorted['cluster_similarity_value']=cluster_similarity_value;  col=df_sorted.columns\n",
    "    \n",
    "    grp = df_sorted.sort_values('Cluster').groupby(['Cluster'],as_index=False)\n",
    "    \n",
    "    temp_more =[]\n",
    "    temp_less  =[]\n",
    "    for i in range(n):\n",
    "        cluster = grp.get_group(i)\n",
    "        cluster_mean = cluster['cluster_similarity_value'].mean()\n",
    "        cluster_std = cluster['cluster_similarity_value'].std()\n",
    "        comp_fact = cluster_mean + cluster_std/4\n",
    "        for i in range(len(cluster)):\n",
    "            if (cluster.iloc[i]['cluster_similarity_value']<comp_fact):\n",
    "                temp_less.append(cluster.iloc[i])\n",
    "            else:\n",
    "                temp_more.append(cluster.iloc[i])\n",
    "    df_more_similar=pd.DataFrame(temp_more,columns=col)\n",
    "    df_less_similar=pd.DataFrame(temp_less,columns=col)\n",
    "    \n",
    "    \n",
    "    Result = df_more_similar.sort_values('Cluster').groupby(['Cluster'],as_index=False).apply(lambda x: x.sample(1)) \n",
    "    Result = Result.reset_index().drop(['level_0','level_1'],axis=1)\n",
    "    Result = Result.append(df_less_similar)\n",
    "    Result = Result.sort_values(by='Cluster')\n",
    "    Result = Result.reset_index().drop(['index'],axis=1)\n",
    "    \n",
    "    \n",
    "    df_dict[cat] = Result\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat,data in df_dict.items():\n",
    "    outname =cat+'.csv'\n",
    "    x=r\"C:\\Users\\drago\\Documents\\GitHub\\Summer-Project\\Entertainment\\More from Entertainment\\Categorized Output\\ \"\n",
    "    if not os.path.exists(x[:-1]):\n",
    "        os.mkdir(x[:-1])\n",
    "    date_today= Today_date +'\\ '\n",
    "    outdir=x[:-1]+ date_today[:-1]\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir) \n",
    "    fullname = os.path.join(outdir, outname) \n",
    "    \n",
    "    data.to_csv(fullname,index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
